import settings

import json
from datetime import datetime
from flask import Flask, render_template, request, redirect, url_for, jsonify

# AI ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

app = Flask(__name__)
app.template_folder = settings.BACKEND_HOME / "templates"
app.static_folder = settings.BACKEND_HOME / "static"
app.static_url_path = "/static"

# ----------------------------------------------------
# [ì„¤ì •] ì‚¬ìš©ì ì´ë¦„ ë§¤í•‘ (IP -> ë³„ëª…)
# ----------------------------------------------------
user_ip_map = {}
nickname_list = [
    "Alice",
    "Bob",
    "Charlie",
    "David",
    "Eve",
    "Frank",
    "Grace",
    "Heidi",
    "Ivan",
    "Judy",
    "Kevin",
    "Lily",
    "Mallory",
    "Niaj",
    "Oscar",
    "Peggy",
]


def get_nickname(ip_address):
    if ip_address not in user_ip_map:
        idx = len(user_ip_map) % len(nickname_list)
        user_ip_map[ip_address] = nickname_list[idx]
    return user_ip_map[ip_address]


# ----------------------------------------------------
# [AI ì¤€ë¹„] ëª¨ë¸ ë¡œë”©
# ----------------------------------------------------
print("Loading AI Model...")

device = torch.device("cpu")

try:
    tokenizer = AutoTokenizer.from_pretrained(settings.USE_PRETRAINED)
    model = AutoModelForSequenceClassification.from_pretrained(
        settings.USE_PRETRAINED, num_labels=6
    )

    checkpoint = torch.load(
        settings.MODEL_HOME / settings.USE_LOCAL_MODEL / settings.USE_PT_NAME,
        map_location=device,
        weights_only=False,
    )
    state_dict = checkpoint.get("state_dict", checkpoint)
    model.load_state_dict(state_dict, strict=False)
    model.to(device)
    model.eval()
    print("âœ… AI Model Loaded Successfully!")
except Exception as e:
    print(f"âš ï¸ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ (ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤): {e}")
    model = None


# ----------------------------------------------------
# [AI ê¸°ëŠ¥ 1] ê°ì • ë¶„ì„ í•¨ìˆ˜
# ----------------------------------------------------
def analyze_sentiment(text):
    if model is None:
        return "ğŸ˜", "neutral"

    try:
        encoded = tokenizer(
            text,
            padding="max_length",
            truncation=True,
            max_length=140,
            return_tensors="pt",
        )
        input_ids = encoded["input_ids"].to(device)
        attention_mask = encoded["attention_mask"].to(device)

        with torch.no_grad():
            output = model(input_ids=input_ids, attention_mask=attention_mask)

        pred_id = int(torch.argmax(output.logits, dim=-1).cpu().item())

        label_map = {
            0: "happy",
            1: "angry",
            2: "sad",
            3: "fear",
            4: "surprise",
            5: "neutral",
        }
        emoji_map = {
            "happy": "ğŸ˜Š",
            "angry": "ğŸ¤¬",
            "sad": "ğŸ˜¢",
            "fear": "ğŸ˜±",
            "surprise": "ğŸ˜§",
            "neutral": "ğŸ˜",
        }

        label_text = label_map[pred_id]
        emoji = emoji_map[label_text]
        return emoji, label_text
    except Exception as exc:
        print(f"error while analyzing sentiment: {exc}")
        return "ğŸ˜", "neutral"


# ----------------------------------------------------
# [AI ê¸°ëŠ¥ 2] ì‚¬ë¬¼ ì¸ì‹ ë§¤í•‘ í•¨ìˆ˜
# ----------------------------------------------------
def detect_target_object(text):
    text = text.lower()
    mapping = {
        "bed": [
            "åºŠ",
            "bed",
            "shuijiao",
            "ç¡è§‰",
            "åºŠå«",
            "åºŠå•",
            "æ•å¤´",
            "è¢«å­",
            "é“º",
            "å¡Œ",
        ],
        "couch": ["æ²™å‘", "sofa", "couch", "æ²™ç™¼", "åå«", "è½¯æ¤…", "èººæ¤…"],
        "chair": ["æ¤…å­", "chair", "seat", "åº§", "å‡³å­", "æ¿å‡³", "é èƒŒæ¤…", "è½¬æ¤…"],
        "dining table": [
            "é¤æ¡Œ",
            "table",
            "æ¡Œå­",
            "é£Ÿæ¡Œ",
            "é¥­æ¡Œ",
            "èŒ¶å‡ ",
            "å°å­",
            "æ¡ˆå­",
            "å†™å­—å°",
            "ä¹¦æ¡Œ",
        ],
        "toilet": [
            "é©¬æ¡¶",
            "toilet",
            "å«ç”Ÿé—´",
            "å•æ‰€",
            "æ´—æ‰‹é—´",
            "èŒ…æˆ¿",
            "ä¾¿æ± ",
            "åä¾¿å™¨",
            "å«æµ´",
        ],
        "tv": ["ç”µè§†", "tv", "monitor", "screen", "å±å¹•", "æ˜¾ç¤ºå™¨", "å½©ç”µ", "æŠ•å½±"],
        "laptop": ["ç¬”è®°æœ¬", "ç”µè„‘", "computer", "PC", "ç¬”ç”µ", "macbook", "æ‰‹æç”µè„‘"],
        "mouse": ["é¼ æ ‡", "mouse", "æ»‘é¼ "],
        "keyboard": ["é”®ç›˜", "keyboard", "é”®ç›¤"],
        "cell phone": ["æ‰‹æœº", "phone", "ç”µè¯", "æ‰‹æç”µè¯", "æ™ºèƒ½æœº", "iphone", "åä¸º"],
        "microwave": ["å¾®æ³¢ç‚‰", "microwave", "çƒ­é¥­", "çƒ¤ç®±"],
        "refrigerator": ["å†°ç®±", "fridge", "å†°æŸœ", "å†·è—"],
        "clock": ["æ—¶é’Ÿ", "clock", "é’Ÿè¡¨", "é—¹é’Ÿ", "æŒ‚é’Ÿ"],
        "potted plant": ["èŠ±", "plant", "è‰", "ç›†æ ½", "æ¤ç‰©", "ç»¿æ¤", "èŠ±è‰", "æ ‘"],
        "book": ["ä¹¦", "book", "æœ¬å­", "æ•™æ", "è¯¾æœ¬", "è¯»ç‰©", "æ‚å¿—", "å°è¯´"],
        "trash can": ["åƒåœ¾æ¡¶", "trash", "åºŸç‰©ç®±", "çº¸ç¯“"],
        "lamp": ["ç¯", "lamp", "å°ç¯", "è·¯ç¯", "ç…§æ˜", "å…‰"],
        "door": ["é—¨", "door", "é—¨å£", "å¤§é—¨", "æˆ¿é—¨"],
        "wardrobe": [
            "è¡£æŸœ",
            "wardrobe",
            "closet",
            "æŸœå­",
            "å¤§è¡£æŸœ",
            "å‚¨ç‰©æŸœ",
            "è¡£æœ",
            "æŒ‚è¡£",
        ],
    }

    found_targets = []
    for yolo_class, keywords in mapping.items():
        for keyword in keywords:
            if keyword in text:
                if yolo_class not in found_targets:
                    found_targets.append(yolo_class)
    return found_targets


# ì„ì‹œ ë°˜ì˜êµ¬ DB (ë¹„íš¨ìœ¨)
class ReviewDB:
    def __init__(self, load=str(settings.BACKEND_HOME / "review.json")):
        self._load = load

    def load(self):
        with open(self._load, "r") as j:
            self._reviews = json.load(j)

    def save(self):
        self.load()
        with open(self._load, "w") as j:
            j.write(json.dumps(self._reviews))

    def new(self, review):
        self.load()
        self._reviews.insert(0, review)
        self.save()

    def get(self) -> list[dict]:
        self.load()
        return self._reviews


json_db = ReviewDB()


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/panorama")
def panorama():
    return render_template("panorama.html")


# ----------------------------------------------------
# [í•µì‹¬ ë³€ê²½] ë¦¬ë·° ì œì¶œ ë° ë¶„ì„ ë¼ìš°íŠ¸
# ----------------------------------------------------
@app.route("/submit_review", methods=["POST"])
def submit_review():
    full_review = request.form.get("review_content", "")
    rating = int(request.form.get("rating", 3))

    # 1. IP ê¸°ë°˜ ë‹‰ë„¤ì„ ìƒì„±
    user_ip = request.remote_addr
    user_name = get_nickname(user_ip)

    # 2. ê°ì • ë¶„ì„ (ì „ì²´ ë¬¸ì¥ ê¸°ì¤€)
    main_emoji, _ = analyze_sentiment(full_review)

    # 3. ì‚¬ë¬¼ ì¸ì‹
    found_targets = detect_target_object(full_review)

    sub_reviews = []

    # 4. ê°€êµ¬ë³„ ë¦¬ë·° ë°ì´í„° ìƒì„±
    for target in found_targets:
        sub_reviews.append(
            {"target": target, "segment_text": full_review, "emoji": main_emoji}
        )

    # 5. DB ì €ì¥
    new_review = {
        "name": user_name,
        "rating": rating,
        "text": full_review,
        "sub_reviews": sub_reviews,
        # â˜… [ìˆ˜ì •ë¨] ì „ì²´ ê°ì • ì´ëª¨í‹°ì½˜ì„ ë³„ë„ë¡œ ì €ì¥ (ê¸°íƒ€ ë¦¬ë·° í‘œì‹œìš©)
        "main_emoji": main_emoji,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }

    # ìµœì‹  ë¦¬ë·°ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì €ì¥
    json_db.new(new_review)
    return redirect(url_for("index"))


@app.route("/api/reviews", methods=["GET"])
def api_reviews():
    return jsonify(json_db.get())


if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=9000)
